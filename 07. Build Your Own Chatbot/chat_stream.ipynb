{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 16:13:43.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.919 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.921 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.922 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.924 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.926 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.927 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.930 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.931 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.937 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.940 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.941 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.942 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.945 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.947 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.949 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.950 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.951 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.955 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.999 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:43.999 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:44.000 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:44.000 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-14 16:13:44.001 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Youtube Streamlit Playlist\n",
    "# https://www.youtube.com/watch?v=hff2tHUzxJM&list=PLc2rvfiptPSSpZ99EnJbH5LjTJ_nOoSWW\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "from dotenv import load_dotenv # langfuse or opik\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "                                        SystemMessagePromptTemplate,\n",
    "                                        HumanMessagePromptTemplate,\n",
    "                                        ChatPromptTemplate,\n",
    "                                        MessagesPlaceholder\n",
    "                                        )\n",
    "\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv('../env')\n",
    "\n",
    "\n",
    "st.title(\"Make Your Own Chatbot\")\n",
    "st.write(\"Chat with me! Catch me at https://youtube.com/kgptalkie\")\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:3b'\n",
    "\n",
    "user_id = st.text_input(\"Enter your user id\", \"laxmikant\")\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///chat_history.db\")\n",
    "\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state.chat_history = []\n",
    "\n",
    "if st.button(\"Start New Conversation\"):\n",
    "    st.session_state.chat_history = []\n",
    "    history = get_session_history(user_id)\n",
    "    history.clear()\n",
    "\n",
    "\n",
    "for message in st.session_state.chat_history:\n",
    "    with st.chat_message(message['role']):\n",
    "        st.markdown(message['content'])\n",
    "\n",
    "\n",
    "### LLM Setup\n",
    "llm = ChatOllama(base_url=base_url, model=model)\n",
    "\n",
    "system = SystemMessagePromptTemplate.from_template(\"You are helpful assistant.\")\n",
    "human = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "\n",
    "messages = [system, MessagesPlaceholder(variable_name='history'), human]\n",
    "\n",
    "prompt = ChatPromptTemplate(messages=messages)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "runnable_with_history = RunnableWithMessageHistory(chain, get_session_history, \n",
    "                                                   input_messages_key='input', \n",
    "                                                   history_messages_key='history')\n",
    "\n",
    "def chat_with_llm(session_id, input):\n",
    "    for output in runnable_with_history.stream({'input': input}, config={'configurable': {'session_id': session_id}}):\n",
    "\n",
    "        yield output\n",
    "\n",
    "\n",
    "prompt = st.chat_input(\"What is up?\")\n",
    "# st.write(prompt)\n",
    "\n",
    "if prompt:\n",
    "    st.session_state.chat_history.append({'role': 'user', 'content': prompt})\n",
    "\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        response = st.write_stream(chat_with_llm(user_id, prompt))\n",
    "\n",
    "    st.session_state.chat_history.append({'role': 'assistant', 'content': response})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
