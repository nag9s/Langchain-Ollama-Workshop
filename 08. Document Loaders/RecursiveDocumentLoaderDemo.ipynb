{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -qU langchain-community beautifulsoup4 lxml langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv('./../env')\n",
    "# os.environ['LANGSMITH_ENDPOINT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Load Documents from Python Documentation\n",
    "def bs4_extractor(html: str) -> str:\n",
    "    \"\"\"Custom extractor to clean HTML content\"\"\"\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    # Remove script, style, and navigation elements\n",
    "    for script in soup([\"script\", \"style\", \"nav\", \"header\", \"footer\"]):\n",
    "        script.decompose()\n",
    "    return soup.get_text(strip=True)\n",
    "\n",
    "loader = RecursiveUrlLoader(\n",
    "    \"https://docs.python.org/3/tutorial/\",  # Specific tutorial section\n",
    "    max_depth=2,  # Crawl up to 2 levels deep\n",
    "    extractor=bs4_extractor,  # Use custom extractor for cleaner text\n",
    "    timeout=15,  # Increased timeout\n",
    "    prevent_outside=True  # Stay within the Python docs domain\n",
    ")\n",
    "\n",
    "# Load the documents\n",
    "docs = loader.load()\n",
    "\n",
    "# Print basic document information\n",
    "print(f\"Total documents loaded: {len(docs)}\")\n",
    "for doc in docs[:3]:  # Print first 3 document details\n",
    "    print(f\"Source: {doc.metadata.get('source', 'N/A')}\")\n",
    "    print(f\"Title: {doc.metadata.get('title', 'N/A')}\")\n",
    "    print(f\"Content length: {len(doc.page_content)} characters\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set up Ollama for Document Analysis\n",
    "# Ensure you've pulled the model first: `ollama pull llama3`\n",
    "llm = OllamaLLM(model='llama3.2:1b')\n",
    "\n",
    "# Step 3: Create a Chain for Documentation Analysis\n",
    "analysis_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert Python documentation analyst.\"),\n",
    "    (\"human\", \"\"\"Carefully analyze the Python tutorial documentation and provide:\n",
    "    1. Key learning points for Python beginners\n",
    "    2. Important programming concepts covered\n",
    "    3. Unique features of Python highlighted in the documentation\n",
    "    4. Recommended learning path\n",
    "\n",
    "    Documentation:\n",
    "    {docs}\"\"\")\n",
    "])\n",
    "\n",
    "# Create the analysis chain\n",
    "analysis_chain = analysis_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Combine first few documents to stay within token limits\n",
    "combined_docs = \" \".join([doc.page_content for doc in docs[:5]])\n",
    "\n",
    "# Perform analysis\n",
    "analysis_result = analysis_chain.invoke({\"docs\": combined_docs})\n",
    "print(\"\\n--- Python Documentation Analysis ---\")\n",
    "print(analysis_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create an Interactive Documentation Query Chain\n",
    "query_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant specializing in Python documentation.\"),\n",
    "    (\"human\", \"Based on the documentation, {query}\")\n",
    "])\n",
    "\n",
    "query_chain = query_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Example interactive queries\n",
    "queries = [\n",
    "    \"Explain the key differences between lists and tuples in Python\",\n",
    "    \"Describe the basic syntax for creating functions\",\n",
    "    \"What are the main control flow tools in Python?\"\n",
    "]\n",
    "\n",
    "print(\"\\n--- Interactive Documentation Queries ---\")\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    response = query_chain.invoke({\"query\": query, \"docs\": combined_docs})\n",
    "    print(\"Response:\", response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Extract Structured Information\n",
    "def extract_key_sections(documents):\n",
    "    \"\"\"Extract key sections from the documentation\"\"\"\n",
    "    sections = {\n",
    "        \"basic_syntax\": [],\n",
    "        \"data_structures\": [],\n",
    "        \"functions\": [],\n",
    "        \"control_flow\": [],\n",
    "        \"classes\": []\n",
    "    }\n",
    "    \n",
    "    for doc in documents:\n",
    "        content = doc.page_content.lower()\n",
    "        \n",
    "        # Identify and categorize sections\n",
    "        if re.search(r'\\bdef\\b|\\bfunction\\b|\\bmethod\\b', content):\n",
    "            sections[\"functions\"].append(doc)\n",
    "        \n",
    "        if re.search(r'\\blist\\b|\\btuple\\b|\\bdict\\b|\\bset\\b', content):\n",
    "            sections[\"data_structures\"].append(doc)\n",
    "        \n",
    "        if re.search(r'\\bif\\b|\\belse\\b|\\bwhile\\b|\\bfor\\b|\\bbreak\\b|\\bcontinue\\b', content):\n",
    "            sections[\"control_flow\"].append(doc)\n",
    "        \n",
    "        if re.search(r'\\bclass\\b|\\binheritance\\b|\\bobject-oriented\\b', content):\n",
    "            sections[\"classes\"].append(doc)\n",
    "        \n",
    "        # Basic syntax detection\n",
    "        if re.search(r'\\bprint\\b|\\bassignment\\b|\\bindentation\\b', content):\n",
    "            sections[\"basic_syntax\"].append(doc)\n",
    "    \n",
    "    return sections\n",
    "\n",
    "# Extract key sections\n",
    "key_sections = extract_key_sections(docs)\n",
    "\n",
    "# Print out the extracted sections\n",
    "print(\"\\n--- Extracted Documentation Sections ---\")\n",
    "for section, section_docs in key_sections.items():\n",
    "    print(f\"\\n{section.replace('_', ' ').title()} Section:\")\n",
    "    print(f\"Number of documents: {len(section_docs)}\")\n",
    "    \n",
    "    # Print sources for each section\n",
    "    for doc in section_docs[:2]:  # Print first 2 sources per section\n",
    "        print(f\"- Source: {doc.metadata.get('source', 'N/A')}\")\n",
    "\n",
    "# Bonus: Create a summary of each section\n",
    "section_summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert Python documentation analyst.\"),\n",
    "    (\"human\", \"\"\"Provide a concise summary of the {section_name} section based on the following content:\n",
    "\n",
    "{section_content}\n",
    "\n",
    "Focus on key points, important concepts, and practical usage.\"\"\")\n",
    "])\n",
    "\n",
    "section_summary_chain = section_summary_prompt | llm | StrOutputParser()\n",
    "\n",
    "print(\"\\n--- Section Summaries ---\")\n",
    "for section_name, section_docs in key_sections.items():\n",
    "    # Combine content of documents in this section\n",
    "    section_content = \" \".join([doc.page_content for doc in section_docs[:3]])\n",
    "    \n",
    "    print(f\"\\n{section_name.replace('_', ' ').title()} Summary:\")\n",
    "    try:\n",
    "        summary = section_summary_chain.invoke({\n",
    "            \"section_name\": section_name.replace('_', ' '),\n",
    "            \"section_content\": section_content\n",
    "        })\n",
    "        print(summary)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary: {e}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
